{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'/kaggle/input/general-titanic-dataset/titanic.csv' does not exist: b'/kaggle/input/general-titanic-dataset/titanic.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9e2cbcadedbf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/kaggle/input/general-titanic-dataset/titanic.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../input/titanic/test.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m#training set has labels and is usde to train our model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'/kaggle/input/general-titanic-dataset/titanic.csv' does not exist: b'/kaggle/input/general-titanic-dataset/titanic.csv'"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n",
    "\n",
    "#!/usr/bin/env python\n",
    "\n",
    "import codecs\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.stats import norm\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "import pandas as pd\n",
    "import matplotlib.backends.backend_pdf\n",
    "import csv\n",
    "import math\n",
    "\n",
    "data = pd.read_csv(\"/kaggle/input/general-titanic-dataset/titanic.csv\")\n",
    "test = pd.read_csv(\"../input/titanic/test.csv\")\n",
    "#training set has labels and is usde to train our model\n",
    "train = pd.read_csv(\"../input/titanic/train.csv\")\n",
    "\n",
    "combined = [train, test]\n",
    "# Family column\n",
    "data['Family'] = (data['SibSp'] > 0) | (data['Parch'] > 0)\n",
    "#print (data[\"Family\"])\n",
    "\n",
    "# Age Analysis\n",
    "#classify as children and adults\n",
    "data['AgeRange'] = pd.cut(data['Age'], [0, 15, 80], labels=['child', 'adult'])\n",
    "#print(data['AgeRange'])\n",
    "# remove missing ages\n",
    "data_clean_age = data.dropna(subset=['Age'])\n",
    "#print(data_clean_age)\n",
    "f = data.groupby(\"Age\")\n",
    "#print(f)\n",
    "mean_age = f.mean()\n",
    "var_age = f.var()\n",
    "std_age = np.sqrt(np.var(data_clean_age))\n",
    "# print (\"Mean: \" + str(np.mean(data_clean_age)))\n",
    "# print (\"Variance: \" +str(np.var(data_clean_age)))\n",
    "# print (\"Standard deviation: \" +str(np.sqrt(np.var(data_clean_age))))\n",
    "# print(mean_age)\n",
    "# print(var_age)\n",
    "# print(std_age)\n",
    "\n",
    "plt.hist(data[\"Age\"], bins = 100, density = True)\n",
    "plt.ylabel('Count')\n",
    "plt.title('Histogram for Age in Titanic')\n",
    "#plt.savefig(\"figure3.pdf\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "#fare analysis\n",
    "data_clean_fare = data.dropna(subset=['Fare'])\n",
    "f = data.groupby(\"Fare\")\n",
    "plt.hist(data[\"Fare\"], bins = 100, density = True)\n",
    "plt.ylabel('Count')\n",
    "plt.title('Histogram for fare in Titanic')\n",
    "#plt.savefig(\"figure4.pdf\")\n",
    "plt.show()\n",
    "mean_fare = f.mean()\n",
    "var_fare = f.var()\n",
    "std_fare = np.sqrt(np.var(data_clean_fare))\n",
    "# print (\"Mean: \" + str(np.mean(data_clean_fare)))\n",
    "# print (\"Variance: \" +str(np.var(data_clean_fare)))\n",
    "# print (\"Standard deviation: \" +str(np.sqrt(np.var(data_clean_fare))))\n",
    "\n",
    "# print(\"Mean fare: \"+str(mean_fare))\n",
    "# print(\"fare Variance:\"+str(var_fare))\n",
    "# print(\"Fare Standard Dev:\"+str(std_fare))\n",
    "\n",
    "\n",
    "\n",
    "# #Normal probability plot for age\n",
    "\n",
    "#counts, start= scipy.stats.probplot(data[\"Age\"],sparams=(), dist='norm', fit=True, plot=None, rvalue=False)\n",
    "#x = np.arange(counts.size) * 1 + start\n",
    "\n",
    "# data[\"Age\"].sort()\n",
    "# X = np.linspace(1.0/len(data[\"Age\"]), 1, len(data[\"Age\"]))\n",
    "# Ppf_age = scipy.stats.norm.ppf(X, mean_age, var_age)\n",
    "counts, start = scipy.stats.probplot(data[\"Age\"],sparams=(),dist = 'norm', fit = True, plot = plt)\n",
    "# plt.plot(Ppf_age, counts, 'ro')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Normalized count')\n",
    "plt.title('Probability plot for age in Titanic')\n",
    "#plt.savefig(\"figure5.pdf\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# #Normal probability plot for fare\n",
    "counts, start = scipy.stats.probplot(data[\"Fare\"],sparams=(),dist = 'norm', fit = True, plot = plt)\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Normalized count')\n",
    "plt.title('Probability plot for Fare in Titanic')\n",
    "#plt.savefig(\"figure6.pdf\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Survival Rates Analysis\n",
    "\n",
    "\n",
    "\n",
    "# remove data not needed\n",
    "data.drop(['PassengerId', 'Parch', 'Ticket', 'Cabin'], axis=1, inplace=True)\n",
    "#survival rates\n",
    "survived_by_class = data.groupby('Pclass')['Survived'].mean()\n",
    "print(survived_by_class)\n",
    "survived_by_sex = data.groupby('Sex')['Survived'].mean()\n",
    "print(survived_by_sex)\n",
    "survived_by_age = data.groupby('AgeRange')['Survived'].mean()\n",
    "print(survived_by_age)\n",
    "\n",
    "# Survival by Gender\n",
    "print(data.groupby(['Sex', 'Survived'])['Survived'].count())\n",
    "\n",
    "# Survival by Class and Gender\n",
    "pd.crosstab([data.Sex, data.Survived], data.Pclass, margins= True).style.background_gradient(cmap='summer_r') \n",
    "\n",
    "fig, (axis1,axis2,axis3) = plt.subplots(1, 3, figsize=(16,6))\n",
    "\n",
    "ax = survived_by_class.plot.bar(ax=axis1, color='#5975A4', title='Survival Rate by Class', sharey=True)\n",
    "ax.set_ylabel('Survival Rate')\n",
    "ax.set_ylim(0.0,1.0)\n",
    "ax = survived_by_sex.plot.bar(ax=axis2, color='#5F9E6E', title='Survival Rate by Sex', sharey=True)\n",
    "ax.set_ylim(0.0,1.0)\n",
    "ax = survived_by_age.plot.bar(ax=axis3, color='#B55D60', title='Survival Rate by Age Range', sharey=True)\n",
    "ax.set_ylim(0.0,1.0)\n",
    "\n",
    "\n",
    "#import Shallow Machine Learning library (i.e., sklearn)\n",
    "#import the Random Forest Algorithm\n",
    "\n",
    "## copied from https://www.kaggle.com/diegogomez92/titanic-diego\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "#this data set has all females surviving and all males not surviving\n",
    "#get ball-park estimate about what feautures are important in the data set\n",
    "gender_submission = pd.read_csv(\"../input/titanic/gender_submission.csv\")\n",
    "\n",
    "#testing data has no labels (i.e., does not include 'Survived' variable)\n",
    "test = pd.read_csv(\"../input/titanic/test.csv\")\n",
    "#training set has labels and is usde to train our model\n",
    "train = pd.read_csv(\"../input/titanic/train.csv\")\n",
    "#show top 5 rows of the data set \n",
    "train.head()\n",
    "#DEPENDENT VARIABLE\n",
    "y = train[\"Survived\"]\n",
    "\n",
    "#INDEPENDENT VARIABLES\n",
    "#the features we will include in our model\n",
    "features = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]\n",
    "X = pd.get_dummies(train[features])\n",
    "X_test = pd.get_dummies(test[features])\n",
    "\n",
    "\n",
    "X_train = train.drop(\"Survived\", axis=1)\n",
    "Y_train = train[\"Survived\"]\n",
    "x_test  = test.drop(\"PassengerId\", axis=1).copy()\n",
    "\n",
    "\n",
    "#More imports for analysis\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# Logistic Regression courtesy of https://www.kaggle.com/startupsci/titanic-data-science-solutions/data\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X, y)\n",
    "Y_pred = logreg.predict(X_test)\n",
    "acc_log = round(logreg.score(X, y) * 100, 2)\n",
    "acc_log\n",
    "\n",
    "\n",
    "# Support Vector Machines\n",
    "\n",
    "svc = SVC()\n",
    "svc.fit(X, y)\n",
    "Y_pred = svc.predict(X_test)\n",
    "acc_svc = round(svc.score(X, y) * 100, 2)\n",
    "acc_svc\n",
    "\n",
    "\n",
    "# Decision Tree\n",
    "\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "decision_tree.fit(X, y)\n",
    "Y_pred = decision_tree.predict(X_test)\n",
    "acc_decision_tree = round(decision_tree.score(X, y) * 100, 2)\n",
    "acc_decision_tree\n",
    "\n",
    "# Random Forest version 1\n",
    "\n",
    "random_forest = RandomForestClassifier(n_estimators=100)\n",
    "random_forest.fit(X, y)\n",
    "Y_pred = random_forest.predict(X_test)\n",
    "random_forest.score(X, y)\n",
    "acc_random_forest = round(random_forest.score(X, y) * 100, 2)\n",
    "acc_random_forest\n",
    "\n",
    "\n",
    "output = pd.DataFrame({\n",
    "        \"PassengerId\": test[\"PassengerId\"],\n",
    "        \"Survived\": Y_pred\n",
    "    })\n",
    "output.to_csv('submission.csv', index=False)\n",
    "print(\"Your first submission was successfully saved!\")\n",
    "\n",
    "\n",
    "#100 random forest trees\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\n",
    "model.fit(X, y) #fit the model\n",
    "predictions = model.predict(X_test) \n",
    "\n",
    "output = pd.DataFrame({'PassengerId': test.PassengerId, 'Survived': predictions})\n",
    "output.to_csv('my_submission.csv', index=False)\n",
    "print(\"Your submission was successfully saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your submission was successfully saved!\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv(\"../input/titanic/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
